{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4279,"status":"ok","timestamp":1713566245671,"user":{"displayName":"Luis Stanley Jovel Portal","userId":"08916066368548829529"},"user_tz":240},"id":"7KwHWuyowcua","outputId":"190f8034-12f8-412c-c4b3-b59667db3719"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Documents/Fulbright Application 2020-2021/Courses/Spring Semester 2024/Deep Decision and Reinforcement Learning/project\n","circle_clock.json         never_seen.json  recover_3.json  recover_6.json\n","circle_counterclock.json  recover_1.json   recover_4.json  snake_2.json\n","eight.json                recover_2.json   recover_5.json  snake.json\n"]}],"source":["# Load the Drive helper and mount\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","%cd /content/drive/MyDrive/Documents/Fulbright\\ Application\\ 2020-2021/Courses/'Spring Semester 2024'/'Deep Decision and Reinforcement Learning'/project\n","%ls demos"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":518188,"status":"ok","timestamp":1713566765061,"user":{"displayName":"Luis Stanley Jovel Portal","userId":"08916066368548829529"},"user_tz":240},"id":"f7uCB7Crx66y","outputId":"8e14557e-8406-4965-c507-3de166a1895c"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating: 100%|██████████| 40/40 [08:31<00:00, 12.78s/it, epoch=40, loss=-118]\n"]}],"source":["import os\n","import json\n","from enum import Enum\n","\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, random_split\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","from tqdm import tqdm\n","\n","from src.agent import BehaviorCloningModel, Constants\n","from src.ppo_agent import PPOModel\n","from src.dataset import Dataset\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","\n","obs_list = torch.tensor([])\n","action_list = torch.tensor([])\n","\n","for file in os.listdir(\"./demos\"):\n","    if file.startswith(\"*\") or file.startswith(\".\"):\n","        continue\n","    with open(f\"./demos/{file}\", \"r\") as f:\n","        data = json.load(f)\n","        for episode in data:\n","            min_length = min(len(episode[0]), len(episode[1]))\n","            obs = episode[0][:min_length]\n","            action = episode[1][:min_length]\n","\n","            if len(obs) == 0 or len(action) == 0:\n","                continue\n","\n","            obs = torch.tensor(obs, dtype=torch.float32)\n","            action = torch.tensor(action, dtype=torch.float32)\n","            obs_list = torch.cat([obs_list, obs])\n","            action_list = torch.cat([action_list, action])\n","\n","dataset = Dataset(Constants.INPUT_SIZE.value, obs_list, action_list, Constants.NUM_HISTORY.value)\n","train_size = int(0.8 * len(dataset))\n","test_size = len(dataset) - train_size\n","train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","# Instantiate model, loss function, and optimizer\n","# model = MultiHistoryNetwork(\n","#     Constants.INPUT_SIZE.value,\n","#     Constants.HIDDEN_SIZE.value,\n","#     Constants.OUTPUT_SIZE.value,\n","#     Constants.NUM_HISTORY.value).to(device)\n","\n","# model = BehaviorCloningModel(\n","#     Constants.NUM_HISTORY.value,\n","#     Constants.INPUT_SIZE.value,\n","#     Constants.OUTPUT_SIZE.value\n","# ).to(device)\n","\n","model = PPOModel(\n","    Constants.NUM_HISTORY.value,\n","    Constants.INPUT_SIZE.value,\n","    Constants.OUTPUT_SIZE.value\n",").to(device)\n","\n","# create a loss function\n","loss_fn = nn.MSELoss().to(device)\n","\n","# create an optimizer\n","optimizer = torch.optim.Adam(model.parameters(), lr=Constants.lr.value)\n","scheduler = ReduceLROnPlateau(optimizer, \"min\", patience=2)\n","# train the model\n","iterator = tqdm(range(1, Constants.EPOCHS.value + 1), total=Constants.EPOCHS.value, desc=\"Training\")\n","\n","for epoch in iterator:\n","    model.train()\n","    iterator.set_description(\"Training\")\n","    for obs, action in train_dataloader:\n","        optimizer.zero_grad()\n","        obs = obs.to(device)\n","        action = action.to(device)\n","        # pred = model(obs)\n","        dist = model(obs)\n","        log_prob = dist.log_prob(action).sum()\n","        loss = -log_prob.mean()\n","        loss.backward()\n","        optimizer.step()\n","\n","    # evaluate the model\n","    iterator.set_description(\"Evaluating\")\n","    model.eval()\n","    with torch.no_grad():\n","        test_loss = 0\n","        for obs, action in test_dataloader:\n","            obs = obs.to(device)\n","            action = action.to(device)\n","            # pred = model(obs)\n","            dist = model(obs)\n","            log_prob = dist.log_prob(action).sum()\n","            loss = -log_prob.mean()\n","            test_loss += loss.item()\n","        test_loss /= len(test_dataloader)\n","    iterator.set_postfix(epoch=epoch, loss=test_loss)\n","    scheduler.step(test_loss)\n","\n","# save the model\n","torch.save(model.state_dict(), f\"pretrained_model_dict_{device}.pt\")\n","torch.save(optimizer.state_dict(), f\"pretrained_optimizer_dict_{device}.pt\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.18"}},"nbformat":4,"nbformat_minor":0}